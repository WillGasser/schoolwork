{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "926ea071",
      "metadata": {
        "id": "926ea071"
      },
      "source": [
        "# COMP 6630 | Assignment 4 | Will Gasser | wbg0023\n",
        "\n",
        "## README\n",
        "Data, Google‑Drive mounting, Assignment4_Data.xlsx.\n",
        "\n",
        "Required libs: pandas, numpy, math, sklearn, matplotlib\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "59abc26f",
      "metadata": {
        "id": "59abc26f"
      },
      "source": [
        "### 1.1 Conditional probability distributions (hand‑calculated)\n",
        "\n",
        "| Feature | μ (Class 0 Apt) | σ (0) | μ (Class 1 H/C) | σ (1) |\n",
        "|---------|---------------:|------:|-----------------:|------:|\n",
        "| Local Price | 7.3327 | 3.6160 | 6.5247 | 3.1241 |\n",
        "| Bathrooms   | 1.2857 | 0.5669 | 1.1923 | 0.4349 |\n",
        "| Land Area   | 6.1039 | 3.2585 | 6.3511 | 2.3079 |\n",
        "| Living area | 1.5050 | 0.7041 | 1.4663 | 0.6205 |\n",
        "| # Garages   | 1.2143 | 0.6986 | 1.1923 | 0.6934 |\n",
        "| # Rooms     | 6.8571 | 1.3452 | 6.4615 | 1.1983 |\n",
        "| # Bedrooms  | 3.4286 | 0.9759 | 3.1538 | 0.6887 |\n",
        "| Age of home | 38.7143|14.6824 | 36.7692|13.0330 |\n",
        "\n",
        "Prior probabilities (training split):  **P(Apartment)=0.35**, **P(House/Condo)=0.65**\n",
        "\n",
        "**Manual work (example)**  \n",
        "For *Bathrooms* (7 Apts, 13 H/C):\n",
        "\n",
        "* counts: Class 0→1.0 ×5, 1.5 ×1, 2.5 ×1 → P(1.0∣0)=5⁄7=0.7143  \n",
        "* counts: Class 1→1.0 ×10, 1.5 ×2, 2.5 ×1 → P(1.0∣1)=10⁄13=0.7692  \n",
        "\n",
        "Gaussian likelihood for x = 1.0 in Class 0:  \n",
        "$$\n",
        "\\frac{1}{0.5669\\sqrt{2\\pi}}\n",
        "      e^{-\\frac{(1-1.2857)^2}{2\\times0.5669^2}}\n",
        "      \\approx 0.6198\n",
        "$$\n",
        "\n",
        "Identical steps (counting then μ/σ) were repeated for # Garages and checked for all other attributes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "d85290f7",
      "metadata": {
        "id": "d85290f7"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "1.2 Hard‑coded Naïve Bayes classifier using constants from 1.1\n",
        "\"\"\"\n",
        "import math, pandas as pd\n",
        "\n",
        "MU = {\n",
        "    0:{'Local Price':7.3327,'Bathrooms':1.2857,'Land Area':6.1039,'Living area':1.5050,\n",
        "       '# Garages':1.2143,'# Rooms':6.8571,'# Bedrooms':3.4286,'Age of home':38.7143},\n",
        "    1:{'Local Price':6.5247,'Bathrooms':1.1923,'Land Area':6.3511,'Living area':1.4663,\n",
        "       '# Garages':1.1923,'# Rooms':6.4615,'# Bedrooms':3.1538,'Age of home':36.7692}\n",
        "}\n",
        "STD = {\n",
        "    0:{'Local Price':3.6160,'Bathrooms':0.5669,'Land Area':3.2585,'Living area':0.7041,\n",
        "       '# Garages':0.6986,'# Rooms':1.3452,'# Bedrooms':0.9759,'Age of home':14.6824},\n",
        "    1:{'Local Price':3.1241,'Bathrooms':0.4349,'Land Area':2.3079,'Living area':0.6205,\n",
        "       '# Garages':0.6934,'# Rooms':1.1983,'# Bedrooms':0.6887,'Age of home':13.0330}\n",
        "}\n",
        "PRIORS={0:0.35,1:0.65}\n",
        "FEATURES=list(MU[0].keys())\n",
        "\n",
        "def gaussian(x, mu, sigma):\n",
        "    if sigma==0:\n",
        "        return 1.0 if x==mu else 1e-10\n",
        "    return (1/(sigma*math.sqrt(2*math.pi)))*math.exp(-((x-mu)**2)/(2*sigma**2))\n",
        "\n",
        "def predict_probs(row):\n",
        "    logp={c:math.log(PRIORS[c]) for c in (0,1)}\n",
        "    for f in FEATURES:\n",
        "        for c in (0,1):\n",
        "            logp[c]+=math.log(max(gaussian(row[f], MU[c][f], STD[c][f]),1e-15))\n",
        "    p0,p1=math.exp(logp[0]), math.exp(logp[1])\n",
        "    total=p0+p1\n",
        "    return {0:p0/total,1:p1/total}\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "excel_path = '/content/drive/MyDrive/Colab Notebooks/Assignment4_Data.xlsx'\n",
        "\n",
        "#  test run\n",
        "train = pd.read_excel(excel_path, sheet_name=0)\n",
        "test  = pd.read_excel(excel_path, sheet_name=1)\n",
        "\n",
        "# binary labels\n",
        "train['Class']=(train['Construction type']!='Apartment').astype(int)\n",
        "test['Class'] =(test['Construction type']!='Apartment').astype(int)\n",
        "\n",
        "correct=0\n",
        "for i,r in test.iterrows():\n",
        "    pr=predict_probs(r)\n",
        "    pred=max(pr,key=pr.get)\n",
        "    correct+=int(pred==r['Class'])\n",
        "    print(f\"Row {i+1}: P0={pr[0]:.4f} P1={pr[1]:.4f} -> Pred={pred}  Actual={r['Class']}\")\n",
        "\n",
        "print(f\"Naïve Bayes accuracy on test split: {correct/len(test):.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PH-fWb2N_0Bv",
        "outputId": "bf7753b4-180b-442c-99ac-4d1571c201e0"
      },
      "id": "PH-fWb2N_0Bv",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Row 1: P0=0.1126 P1=0.8874 -> Pred=1  Actual=0\n",
            "Row 2: P0=0.4580 P1=0.5420 -> Pred=1  Actual=1\n",
            "Row 3: P0=0.1889 P1=0.8111 -> Pred=1  Actual=1\n",
            "Row 4: P0=0.3585 P1=0.6415 -> Pred=1  Actual=0\n",
            "Row 5: P0=0.2151 P1=0.7849 -> Pred=1  Actual=0\n",
            "Naïve Bayes accuracy on test split: 0.40\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ce22be7c",
      "metadata": {
        "id": "ce22be7c"
      },
      "source": [
        "## 2 Decision Tree  \n",
        "\n",
        "### 2.1\n",
        "Using the off-the-shelf DecisionTreeClassifier() the algorithm keeps splitting until every training leaf is pure.  \n",
        "* **Training accuracy = 1.0000** – the tree memorises all 20 training rows.  \n",
        "* **Test accuracy = 0.6000** – on the five unseen houses it gets 3 / 5 correct.  \n",
        "The perfect in-sample score + drop on new data is shows signs of overfitting as the model has captured noise of the training set.  \n",
        "\n",
        "---\n",
        "\n",
        "### 2.2   \n",
        "Max depth was limited:\n",
        "\n",
        "| depth | train acc | test acc |\n",
        "|-------|-----------|----------|\n",
        "| 1 | 0.75 | 0.40 |\n",
        "| 2 | 0.85 | **0.60** |\n",
        "| 3 | 0.95 | 0.60 |\n",
        "| 4-10 | 1.00 | 0.60 |\n",
        "\n",
        "Depth 2 gives the highest test score while still avoiding full memorization.Deeper models keep improving the fit to the tiny training set but do not lift test performance which shows the inclusion of noise.\n",
        "\n",
        "---\n",
        "\n",
        "### 2.3\n",
        "A shallow tree acts like built-in regularization:  \n",
        "\n",
        "* **Fewer leaves → larger sample per leaf** – each decision is supported by several houses, so the rule is more reliable.\n",
        "* **Focus on the strongest predictors** – the first two or three splits usually involve the features with the highest information-gain (here Local Price and Age of home). Less informative variables are ignored.  \n",
        "* **Lower variance** – with only 20 training rows, an unconstrained tree has enormous variance; depth-capping keeps that variance in check, improving generalization.\n",
        "\n",
        "That is why accuracy peaks at a modest depth and then plateaus: we have extracted the useful structure after ~2 levels, everything deeper just memorizes nose.\n",
        "\n",
        "---\n",
        "\n",
        "### 2.4\n",
        "Given the feature vector  \n",
        "\n",
        "| Feature | Value |\n",
        "|---------|-------|\n",
        "| Local Price | 9.0384 |\n",
        "| Bathrooms | 1 |\n",
        "| Land Area | 7.8 |\n",
        "| Living area | 1.5 |\n",
        "| # Garages | 1.5 |\n",
        "| # Rooms | 7 |\n",
        "| # Bedrooms | 3 |\n",
        "| Age of home | 23 |\n",
        "\n",
        "the depth-2 tree follows two comparisons:\n",
        "\n",
        "1. **Local Price ≤ 8.36 ?** – *No* → right branch  \n",
        "2. **Age of home ≤ 37.5 ?** – *Yes* → reach leaf labelled **0**\n",
        "\n",
        "Leaf 0 was created from several “Apartment” examples, so the model assigns a ≈ 1.00 to Class 0.  \n",
        "\n",
        "**Prediction:** Apartment (Class 0) with essentially full confidence.\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "6009e1d7",
      "metadata": {
        "id": "6009e1d7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf7d11ee-a8a8-4f7f-f5ed-c14873758ef7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Depth | Train | Test\n",
            "    1 | 0.75  | 0.40\n",
            "    2 | 0.85  | 0.60\n",
            "    3 | 0.95  | 0.60\n",
            "    4 | 0.95  | 0.60\n",
            "    5 | 1.00  | 0.60\n",
            "    6 | 1.00  | 0.60\n",
            "    7 | 1.00  | 0.60\n",
            "    8 | 1.00  | 0.60\n",
            "    9 | 1.00  | 0.60\n",
            "   10 | 1.00  | 0.60\n",
            "\n",
            "Depth chosen: 2\n",
            "Prediction: 0 Proba: [1. 0.]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "import pandas as pd, numpy as np\n",
        "\n",
        "train = pd.read_excel(excel_path, sheet_name=0)\n",
        "test  = pd.read_excel(excel_path, sheet_name=1)\n",
        "train['Class']=(train['Construction type']!='Apartment').astype(int)\n",
        "test['Class'] =(test['Construction type']!='Apartment').astype(int)\n",
        "\n",
        "features=['Local Price','Bathrooms','Land Area','Living area','# Garages','# Rooms','# Bedrooms','Age of home']\n",
        "Xtr,ytr=train[features],train['Class']\n",
        "Xte,yte=test[features],test['Class']\n",
        "\n",
        "print(\"Depth | Train | Test\")\n",
        "best_depth,best_score=1,0\n",
        "for d in range(1,11):\n",
        "    dt=DecisionTreeClassifier(max_depth=d,random_state=42).fit(Xtr,ytr)\n",
        "    tr,te=accuracy_score(ytr,dt.predict(Xtr)),accuracy_score(yte,dt.predict(Xte))\n",
        "    print(f\"{d:>5} | {tr:.2f}  | {te:.2f}\")\n",
        "    if te>best_score:\n",
        "        best_score, best_depth = te, d\n",
        "\n",
        "# inference\n",
        "best=DecisionTreeClassifier(max_depth=best_depth,random_state=42).fit(Xtr,ytr)\n",
        "query=pd.DataFrame({'Local Price':[9.0384],'Bathrooms':[1],'Land Area':[7.8],'Living area':[1.5],\n",
        "                    '# Garages':[1.5],'# Rooms':[7],'# Bedrooms':[3],'Age of home':[23]})\n",
        "print(\"\\nDepth chosen:\",best_depth)\n",
        "print(\"Prediction:\",best.predict(query)[0],\"Probbility:\",best.predict_proba(query)[0])\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}